# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
#
# SPDX-License-Identifier: MIT

specVersion: v2
specMinorVersion: 2
meta:
  name: tilegym
  image: project-tilegym
  description: "TileGym Transformers Inference"
  createdOn: "2026-02-04T16:00:00Z"
  defaultBranch: main
layout:
  - path: code/
    type: code
    storage: git
  - path: models/
    type: models
    storage: gitlfs
  - path: data/
    type: data
    storage: gitlfs
environment:
  base:
    registry: nvcr.io
    image: nvidia/cuda:13.1.0-devel-ubuntu22.04
    name: CUDA 13.1 Devel Base
    os: linux
    os_distro: ubuntu
    os_distro_release: "22.04"
    schema_version: v2
    # ADD THESE: AI Workbench needs to know where binaries are located
    package_managers:
      - name: apt
        binary_path: /usr/bin/apt
      - name: pip
        binary_path: /usr/bin/pip
  # Move your setup commands here so they run during build
  setup:
    - python -m pip install --upgrade pip setuptools wheel
    - pip install --no-cache-dir --pre "torch==2.9.1" --index-url https://download.pytorch.org/whl/cu130
    - pip install --no-cache-dir cuda-tile
    - pip install --no-cache-dir --no-deps accelerate
    - pip install -e .  # Equivalent to your 'source' target install

# Replicates your ENV and directory creation
variables:
  - name: PYTHONUNBUFFERED
    value: "1"
  - name: HF_HOME
    value: "/workspace/.cache/huggingface"
  - name: TILEGYM_MODEL_CACHE_DIR
    value: "/workspace/.cache"

execution:
    apps:
        - name: jupyterlab
          type: jupyterlab
          class: webapp
          start_command: jupyter lab --allow-root --port 8888 --ip 0.0.0.0 --no-browser --NotebookApp.base_url=\$PROXY_PREFIX --NotebookApp.default_url=/lab --notebook-dir=/project/
          health_check_command: '[ \$(echo url=\$(jupyter lab list 2>&1 | head -n 2 | tail -n 1 | cut -f1 -d'''' '''' | grep -v ''''Currently'''' | sed ''''s@/?@/lab?@g'''') | curl -o /dev/null -s -w ''''%{http_code}'''' --config -) == ''''200'''' ]'
          stop_command: jupyter lab stop 8888
          user_msg: ""
          logfile_path: ""
          timeout_seconds: 60
          icon_url: ""
          webapp_options:
            autolaunch: true
            port: "8888"
            proxy:
                trim_prefix: false
            url_command: jupyter lab list 2>&1 | head -n 2 | tail -n 1 | cut -f1 -d' ' | grep -v 'Currently'
    resources:
        gpu:
            requested: 1
        sharedMemoryMB: 1024
    secrets: []
    mounts:
        - type: project
          target: /project/
          description: Project directory
          options: rw
        - type: volume
          target: /mnt/cache/
          description: Huggingface cache root
          options: ""